{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad2ea9e",
   "metadata": {},
   "source": [
    "# AI Project Tree (Starter) â€” Project Tree\n",
    "\n",
    "_Snapshot generated: 2025-09-17T06:16:46_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9b3c2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 1. Proof of Data Generation\n",
    "\n",
    "* In code: `make_burgers_batch`, `make_ut_eq_u2_batch`, `make_model_batch` (synthetic), or DeepXDEâ€™s `TimePDE` solver block.\n",
    "* What to do:\n",
    "\n",
    "  * Run the numerical/synthetic generator â†’ visualize trajectories.\n",
    "  * Check conservation (e.g. compute âˆ«u dx or âˆ«uÂ² dx over time).\n",
    "  * For closed-form (`ut = uÂ²` batch), directly plug back into PDE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966aa0d7",
   "metadata": {},
   "source": [
    "\n",
    "## Roots\n",
    "\n",
    "- **[Inbox (quick captures)](C:\\Users\\sami\\Documents\\PDENets\\notebook\\tree_template\\tsk_a1290e7d.md)**  â€” _task, open_\n",
    "- **[Proof-of-Data Generation for Burgers (Rusanov, periodic)](tsk_859c942d.md)**  â€” _task, open_\n",
    "  - **[Deliberation: Why Rusanov vs spectral?](dlb_f7f9aed3.md)**  â€” _deliberation, open_\n",
    "  - **[Step plan (AI-generated)](nte_87dab8d8.md)**  â€” _note, open_\n",
    "  - **[Decision: Use Rusanov + refinement study](res_a1704e6b.md)**  â€” _result, open_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea272d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 2. Proof of Interpolation Accuracy\n",
    "\n",
    "* In code: `SimpleMLP` trained via `trainer.train(..., train_pde=False)`.\n",
    "* What to do:\n",
    "\n",
    "  * Evaluate on finer grid, compare to generatorâ€™s â€œground truthâ€.\n",
    "  * Report LÂ² (mean-squared) and Lâˆ (max error).\n",
    "  * Vary mesh size to see if error decays with refinement.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 3. Proof of Smoothness of Interpolant\n",
    "\n",
    "* In code: `torch.autograd.grad` inside `_build_features`.\n",
    "* What to do:\n",
    "\n",
    "  * Compute âˆ«||âˆ‡u||Â² dxdt (numerical integration over mesh).\n",
    "  * Report max |âˆ‡u| as Lipschitz proxy.\n",
    "  * Compare with expected PDE behavior (e.g. smooth sinusoidal â†’ steepening â†’ shock).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 4. Proof of Autograd Derivatives\n",
    "\n",
    "* In code: already available (`torch.autograd.grad` in `_build_features`).\n",
    "* What to do:\n",
    "\n",
    "  * Take trained `u_model`.\n",
    "  * Compute u\\_x (autograd).\n",
    "  * Approximate u\\_x with finite difference on the same grid.\n",
    "  * Compare via LÂ², Lâˆ norms.\n",
    "  * Confirms autograd â‰ˆ numerical differencing for your interpolant.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 5. Proof of PDE Satisfaction\n",
    "\n",
    "* In code: PDE residual built inside `step()` via\n",
    "\n",
    "  ```python\n",
    "  u_t / (a_hat**2) vs v_out\n",
    "  ```\n",
    "\n",
    "  and for DeepXDE: `pde(x,u)` returning residual.\n",
    "* What to do:\n",
    "\n",
    "  * After training purely on data, compute residual R = u\\_t + u u\\_x (or viscous version).\n",
    "  * Report norm over mesh (LÂ², Lâˆ).\n",
    "  * This tells whether your interpolant satisfies the PDE approximately.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 6. Proof of Symbolic Discovery\n",
    "\n",
    "* In code: `symMLP` (linear) + `extract_symbolic_pde_deep(trainer)`.\n",
    "* What to do:\n",
    "\n",
    "  * Train with `selected_derivs=('uu','u_x')` or more.\n",
    "  * Run extractor â†’ see coefficients.\n",
    "  * Check if recovered terms align with PDE structure (e.g. Burgers has `uu_x` and `u_xx`).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 7. (Optional) Shock Kinematics\n",
    "\n",
    "* In code: youâ€™ll need to post-process.\n",
    "* What to do:\n",
    "\n",
    "  * Track argmax(|âˆ‡u|) over t in solver vs MLP.\n",
    "  * Compare shock speed with Rankineâ€“Hugoniot jump condition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32236c67",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
